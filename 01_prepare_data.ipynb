{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1692453/3860224080.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity = pd.read_csv('data/fine_tune_activity.csv', usecols=['Sequence', 'activity', 'Set'])\n",
    "hemolysis = pd.read_csv('data/fine_tune_hemolysis.csv', usecols=['Sequence', 'isNotHemolytic', 'Set'])\n",
    "hemolysis = hemolysis[(hemolysis['isNotHemolytic'] == 0) | (hemolysis['isNotHemolytic'] == 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity = activity.rename(columns={'Sequence': 'sequence', 'activity': 'label', 'Set': 'split_1'})\n",
    "hemolysis = hemolysis.rename(columns={'Sequence': 'sequence', 'isNotHemolytic': 'label', 'Set': 'split_1'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity = activity.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "hemolysis = hemolysis.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add columns with four additional test/train splits (for cross-validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_splits(df):\n",
    "    train_splits = {}\n",
    "    test_splits = {}\n",
    "    for i in range(2, 6):\n",
    "        train_splits[i], test_splits[i] = train_test_split(df.index, test_size=0.25, random_state=i)\n",
    "        df[f'split_{i}'] = 'training'\n",
    "        df.loc[test_splits[i], f'split_{i}'] = 'test'\n",
    "\n",
    "generate_splits(activity)\n",
    "generate_splits(hemolysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity.to_csv('data/activity_clean.csv', index=False)\n",
    "hemolysis.to_csv('data/hemolysis_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate datasets for GPT-3.5 Turbo fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to write data from dataframe to file in the correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json(df, purpose, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        for index, row in df.iterrows():\n",
    "\n",
    "            sequence = row['sequence'] + ' ->'\n",
    "            label = row['label']\n",
    "                \n",
    "            system_role = {\"role\": \"system\", \"content\": f\"You are a model that predicts {purpose} from an amino acid sequence.\"}\n",
    "            user_message = {\"role\": \"user\", \"content\": str(sequence)}\n",
    "            system_message = {\"role\": \"assistant\", \"content\": str(label)}\n",
    "            \n",
    "            messages = []\n",
    "            messages.append(system_role)\n",
    "            messages.append(user_message)\n",
    "            messages.append(system_message)\n",
    "            data = {\"messages\": messages}\n",
    "\n",
    "            f.write(json.dumps(data) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through each of the five splits and write the data to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 6):\n",
    "    write_json(activity[activity[f'split_{i}'] == 'training'], 'activity', f'data/activity_train_{i}.json')\n",
    "    write_json(activity[activity[f'split_{i}'] == 'test'], 'activity', f'data/activity_test_{i}.json')\n",
    "    write_json(hemolysis[hemolysis[f'split_{i}'] == 'training'], 'hemolysis', f'data/hemolysis_train_{i}.json')\n",
    "    write_json(hemolysis[hemolysis[f'split_{i}'] == 'test'], 'hemolysis', f'data/hemolysis_test_{i}.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openaienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
