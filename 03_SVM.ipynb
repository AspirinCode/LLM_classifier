{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from rdkit import Chem\n",
    "from helicity import run_helicity_predictions\n",
    "from hydrophobic_moment import run_hydrophobic_moment_predictions\n",
    "from mapchiral.mapchiral import encode\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score, precision_score, accuracy_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity = pd.read_csv('data/activity_clean.csv')\n",
    "hemolysis = pd.read_csv('data/hemolysis_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helicity and Hydrophobic Moment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helicity prediction using SPIDER3. Some sequences need to be removed for the prediction. For these sequences, helicity is set to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing iteration 0 - SS\n",
      "doing iteration 0 - ASA THETA TAU PHI PSI HSEa CN\n",
      "combining both prediction files\n",
      "doing iteration 1 - SS\n",
      "doing iteration 1 - ASA THETA TAU PHI PSI HSEa CN\n",
      "combining both prediction files\n",
      "Time taken - 174 seconds\n"
     ]
    }
   ],
   "source": [
    "# Remove sequences which won't work for SPIDER3 predictions\n",
    "activity_helicity = activity[['sequence', 'label']]\n",
    "activity_helicity = activity_helicity[activity_helicity['sequence'].str.len() > 1]\n",
    "activity_helicity = activity_helicity[~activity_helicity['sequence'].str.contains('[a-z]')]\n",
    "activity_helicity['helicity'] = run_helicity_predictions(activity_helicity['sequence'], 'spider3', 'dbaasp_activity') \n",
    "\n",
    "hemolysis_helicity = hemolysis[['sequence', 'label']]\n",
    "hemolysis_helicity = hemolysis_helicity[hemolysis_helicity['sequence'].str.len() > 1]\n",
    "hemolysis_helicity = hemolysis_helicity[~hemolysis_helicity['sequence'].str.contains('[a-z]')]\n",
    "hemolysis_helicity['helicity'] = run_helicity_predictions(hemolysis_helicity['sequence'], 'spider3', 'dbaasp_hemolysis')\n",
    "\n",
    "# Merge back the results into the original dataframe\n",
    "activity = pd.merge(activity, activity_helicity, on='sequence', how='left')\n",
    "activity['helicity'] = activity['helicity'].fillna(0)\n",
    "\n",
    "hemolysis = pd.merge(hemolysis, hemolysis_helicity, on='sequence', how='left')\n",
    "hemolysis['helicity'] = hemolysis['helicity'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hydrophobic moment prediction using a python script from Joao Rodrigues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity['hydrophobic_moment'] = activity['sequence'].apply(run_hydrophobic_moment_predictions)\n",
    "hemolysis['hydrophobic_moment'] = hemolysis['sequence'].apply(run_hydrophobic_moment_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helicity and hydrophobic moment are combined into a single feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_features(row):\n",
    "    return [row['helicity'], row['hydrophobic_moment']]\n",
    "\n",
    "activity['features'] = activity.apply(combine_features, axis=1)\n",
    "hemolysis['features'] = hemolysis.apply(combine_features, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAP4C fingerprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the MAP4C fingerprint feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity['map4'] = activity['sequence'].apply(lambda x: encode(Chem.MolFromSequence(x), max_radius=2, n_permutations=2048)) \n",
    "hemolysis['map4'] = hemolysis['sequence'].apply(lambda x: encode(Chem.MolFromSequence(x), max_radius=2, n_permutations=2048))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export data frames and load exported data frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export data frames using the joblib library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_clean/hemolysis_clean_features.pkl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(activity, 'data/activity_clean_features.pkl')\n",
    "joblib.dump(hemolysis, 'data/hemolysis_clean_features.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data frames using the joblib library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity = joblib.load('data/activity_clean_features.pkl')\n",
    "hemolysis = joblib.load('data/hemolysis_clean_features.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Jaccard kernel function for SVM. This kernel function is required for the MAP4C fingerprint. \\\n",
    "Define helper function for the evaluation of the classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_kernel(X, Y=None):\n",
    "    if Y is None:\n",
    "        X = Y\n",
    "    js_allpairs = np.zeros((len(X),len(Y)))\n",
    "    for i,fp1 in enumerate(X):\n",
    "        for j,fp2 in enumerate(Y):\n",
    "            js_allpairs[i,j] = np.float64(np.count_nonzero(fp1 == fp2)) / np.float64(len(fp1))\n",
    "    return js_allpairs\n",
    "\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "    return pd.DataFrame({'roc_auc': [roc_auc], 'accuracy': [accuracy], 'precision': [precision], 'recall': [recall], 'f1': [f1]})\n",
    "\n",
    "def run_cross_validation(df, feature, purpose):\n",
    "\n",
    "    # Initialize the output data frame\n",
    "    df_out = pd.DataFrame()\n",
    "    \n",
    "    # Loop over the five folds\n",
    "    for i in range(1, 6):\n",
    "\n",
    "        # Split the data based on the information in the data frame column\n",
    "        X_train, y_train = df[df[f'split_{i}'] == 'training'][feature].values.tolist(), df[df[f'split_{i}'] == 'training']['label'].values.tolist()\n",
    "        X_test, y_test = df[df[f'split_{i}'] == 'test'][feature].values.tolist(), df[df[f'split_{i}'] == 'test']['label'].values.tolist()\n",
    "\n",
    "        # Train the model \n",
    "        if feature == 'map4':\n",
    "            svm = SVC(C=1, kernel=jaccard_kernel, class_weight='balanced', random_state=42)\n",
    "        elif feature == 'features':\n",
    "            svm = SVC(C=1, kernel='linear', class_weight='balanced', random_state=42)\n",
    "        else:\n",
    "            continue\n",
    "        svm.fit(np.array(X_train), np.array(y_train))\n",
    "\n",
    "        # Export the model \n",
    "        joblib.dump(svm, f'models/SVM/svm_{purpose}_{feature}_fold_{i}.pkl')\n",
    "\n",
    "        # Predict and append to the dataframe\n",
    "        y_pred = svm.predict(X_test)\n",
    "        row = calculate_metrics(y_test, y_pred)\n",
    "\n",
    "        # Append the results to the output dataframe\n",
    "        df_out = pd.concat([df_out, row], ignore_index=True)\n",
    "    \n",
    "    # Add mean and standard deviation\n",
    "    df_out = pd.concat([df_out, pd.DataFrame(df_out.mean()).T], ignore_index=True)\n",
    "    df_out = pd.concat([df_out, pd.DataFrame(df_out.std()).T], ignore_index=True)\n",
    "    df_out.index = [f'fold_{i}' for i in range(1, 6)] + ['mean', 'std']\n",
    "\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5-fold cross-validation on helicity and hydrophobic moment features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_features = run_cross_validation(activity, 'features', 'activity')\n",
    "hemolysis_features = run_cross_validation(hemolysis, 'features', 'hemolysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5-fold cross-validation on MAP4C fingerprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_map4c = run_cross_validation(activity, 'map4', 'activity')\n",
    "hemolysis_map4c = run_cross_validation(hemolysis, 'map4', 'hemolysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_features.to_csv('results/svm_activity_features_5cv.csv')\n",
    "hemolysis_features.to_csv('results/svm_hemolysis_features_5cv.csv')\n",
    "activity_map4c.to_csv('results/svm_activity_map4c_5cv.csv')\n",
    "hemolysis_map4c.to_csv('results/svm_hemolysis_map4c_5cv.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openaienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
