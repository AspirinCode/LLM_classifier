{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, precision_score, accuracy_score, recall_score, f1_score\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI(organization='YOUR ORG',\n",
    "    api_key='YOUR KEY'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload files to OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload training and test datasets prepared in the previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 6):\n",
    "    \n",
    "    client.files.create(\n",
    "      file=open(f'data/activity_train_{i}.json', 'rb'),\n",
    "      purpose='fine-tune'\n",
    "    )\n",
    "    \n",
    "    client.files.create(\n",
    "      file=open(f'data/activity_test_{i}.json', 'rb'),\n",
    "      purpose='fine-tune',\n",
    "    )\n",
    "    \n",
    "    client.files.create(\n",
    "      file=open(f'data/hemolysis_train_{i}.json', 'rb'),\n",
    "      purpose='fine-tune',\n",
    "    )\n",
    "    \n",
    "    client.files.create(\n",
    "      file=open(f'data/hemolysis_test_{i}.json', 'rb'),\n",
    "      purpose='fine-tune',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create fine-tuning jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go on OpenAI files and manually write down the file IDs because I couldn't find a way to do it programmatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ids = {\n",
    "    'activity_train_1': 'file-4QveSliSbmwbW5y0j0XaZDvP',\n",
    "    'activity_test_1': 'file-QlCO8R5IpVTzVFFgWfXvuLWY',\n",
    "    'hemolysis_train_1': 'file-6bF7sJa0ZKTOHNFHYAD6m2lF',\n",
    "    'hemolysis_test_1': 'file-ngbcPNae21fDhbwcXtNXwinp',\n",
    "    'activity_train_2': 'file-9sI9mZ6X1I2HfiUBtNE00rBr',\n",
    "    'activity_test_2': 'file-RJsJfRhBqted2uWd8klnnHoh',\n",
    "    'hemolysis_train_2': 'file-ibMzndIaKmfJfQ5PPiZSL9AU',\n",
    "    'hemolysis_test_2': 'file-g8ccncNCsgY07wNA5u3Tl7aa',\n",
    "    'activity_train_3': 'file-YOnRI80jYtBB4HQ75Po6JOM5',\n",
    "    'activity_test_3': 'file-s8mxQGTOrvBFnlmuuo1sLeKb',\n",
    "    'hemolysis_train_3': 'file-ffVrkoV96Mq9unWXLAlq957o',\n",
    "    'hemolysis_test_3': 'file-Ftgnkd8DCx2LW7G0oki46lRv',\n",
    "    'activity_train_4': 'file-KH4fAnK7PTz5go3URg7Qfni8',\n",
    "    'activity_test_4': 'file-vPINZg9HjpRGzGkk6BmBT4zv',\n",
    "    'hemolysis_train_4': 'file-5rIRI2OTwGWvKYgN2hENWJhc',\n",
    "    'hemolysis_test_4': 'file-6xaNs42tKDHlO3wZx4BVMyCa',\n",
    "    'activity_train_5': 'file-6xRbamt5YYZQBlrpl0azH5nB',\n",
    "    'activity_test_5': 'file-RRGFWTEcHqHm54bdsGWcmBGC',\n",
    "    'hemolysis_train_5': 'file-M49wDxpa1tmFvFiGFY0w6hq2',\n",
    "    'hemolysis_test_5': 'file-eMRwVz9j9TbC4USMQdDbKcJ1',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start fine-tuning jobs using the file IDs (yes manually AGAIN because it's not possible to fine-tune more than 3 models at the same time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.fine_tuning.jobs.create(\n",
    "    training_file=file_ids[f'activity_train_5'],\n",
    "    validation_file=file_ids[f'activity_test_5'],\n",
    "    model='gpt-3.5-turbo',\n",
    "    suffix=f'activity_split_5',\n",
    ")\n",
    "\n",
    "client.fine_tuning.jobs.create(\n",
    "    training_file=file_ids[f'hemolysis_train_5'],\n",
    "    validation_file=file_ids[f'hemolysis_test_5'],\n",
    "    model='gpt-3.5-turbo',\n",
    "    suffix=f'hemolysis_split_5',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the names of the fine-tuned models (manually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ids = {\n",
    "    'activity_split_1': 'ft:gpt-3.5-turbo-0613:reymond-group:activity-split-1:8sqaOXkP',\n",
    "    'hemolysis_split_1': 'ft:gpt-3.5-turbo-0613:reymond-group:hemolysis-split-1:8sqhverN',\n",
    "    'activity_split_2': 'ft:gpt-3.5-turbo-0613:reymond-group:activity-split-2:8ssBwa32',\n",
    "    'hemolysis_split_2': 'ft:gpt-3.5-turbo-0613:reymond-group:hemolysis-split-2:8ssA4hWd',\n",
    "    'activity_split_3': 'ft:gpt-3.5-turbo-0613:reymond-group:activity-split-3:8stvOJgD',\n",
    "    'hemolysis_split_3': 'ft:gpt-3.5-turbo-0613:reymond-group:hemolysis-split-3:8stdCu4f',\n",
    "    'activity_split_4': 'ft:gpt-3.5-turbo-0613:reymond-group:activity-split-4:8svNi6hW',\n",
    "    'hemolysis_split_4': 'ft:gpt-3.5-turbo-0613:reymond-group:hemolysis-split-4:8sunorAI',\n",
    "    'activity_split_5': 'ft:gpt-3.5-turbo-0613:reymond-group:activity-split-5:8svEPfjB',\n",
    "    'hemolysis_split_5': 'ft:gpt-3.5-turbo-0613:reymond-group:hemolysis-split-5:8tu63nlf',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import original datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity = pd.read_csv('data/activity_clean.csv')\n",
    "hemolysis = pd.read_csv('data/hemolysis_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the 5-fold cross-validation of the fine-tuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred):\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "    return pd.DataFrame({'roc_auc': [roc_auc], 'accuracy': [accuracy], 'precision': [precision], 'recall': [recall], 'f1': [f1]})\n",
    "\n",
    "def run_cross_validation(df, purpose):\n",
    "\n",
    "    # Initialize the output data frame\n",
    "    df_out = pd.DataFrame()\n",
    "    \n",
    "    # Loop over the five folds\n",
    "    for i in range(1, 6):\n",
    "\n",
    "        # Split the data based on the information in the data frame column\n",
    "        X_test = df[df[f'split_{i}'] == 'test']['sequence'].tolist()\n",
    "        y_test = df[df[f'split_{i}'] == 'test']['label'].tolist()\n",
    "\n",
    "        # Run predictions\n",
    "        y_pred = []\n",
    "        for idx in range(len(X_test)):\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"ft:gpt-3.5-turbo-0613:reymond-group:activity:8orpwtM0\",\n",
    "                messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"You are a model that predicts {purpose} from an amino acid sequence.\"},\n",
    "                {\"role\": \"user\", \"content\": str(X_test[idx]) + \" ->\"}\n",
    "                ], \n",
    "                temperature=0.0)\n",
    "            y_pred.append(response.choices[0].message.content)\n",
    "        y_pred = [int(x) for x in y_pred]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        row = calculate_metrics(y_test, y_pred)\n",
    "\n",
    "        # Append the results to the output dataframe\n",
    "        df_out = pd.concat([df_out, row], ignore_index=True)\n",
    "    \n",
    "    # Add mean and standard deviation\n",
    "    df_out = pd.concat([df_out, pd.DataFrame(df_out.mean()).T], ignore_index=True)\n",
    "    df_out = pd.concat([df_out, pd.DataFrame(df_out.std()).T], ignore_index=True)\n",
    "    df_out.index = [f'fold_{i}' for i in range(1, 6)] + ['mean', 'std']\n",
    "\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_eval = run_cross_validation(activity, 'antimicrobial activity')\n",
    "hemolysis_eval = run_cross_validation(hemolysis, 'hemolysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_eval.to_csv('results/gpt3-5_activity_5cv.csv')\n",
    "hemolysis_eval.to_csv('results/gpt3-5_hemolysis_5cv.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gptenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
